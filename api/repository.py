import asyncio
import boto3
import os
import uuid
import time
from botocore.exceptions import ClientError

class Repository:
    def __init__(self, region_name=None, conversation_table='ConversationHistory', media_bucket='transformlah-media-files-2025'):
        self.dynamodb_client = boto3.client('dynamodb', region_name=region_name or os.getenv('BEDROCK_REGION'))
        self.s3_client = boto3.client('s3', region_name=region_name or os.getenv('BEDROCK_REGION'))
        self.conversation_table = conversation_table
        self.media_bucket = media_bucket

    async def save_conversation_entry(self, session_id: str, user_id: str, content: str, content_type: str, file_data=None):
        """Saves a conversation entry, including media, to DynamoDB and S3."""
        loop = asyncio.get_event_loop()

        entry = {
            'SessionId': {'S': session_id},
            'Timestamp': {'N': str(int(time.time()))},
            'UserId': {'S': user_id},
            'ContentType': {'S': content_type},
            'Content': {'S': content}
        }
        
        s3_url = None

        # If the content is an image or video, upload it to S3 first
        if file_data and content_type in ['image', 'video']:
            file_name = f"{session_id}/{str(uuid.uuid4())}.{content_type}"

            # Use S3 client to upload the file
            await loop.run_in_executor(None, lambda: self.s3_client.put_object(
                Bucket=self.media_bucket,
                Key=file_name,
                Body=file_data
            ))

            # Store the S3 URL in the DynamoDB item instead of the raw data
            s3_url = f"s3://{self.media_bucket}/{file_name}"
            entry['Content'] = {'S': s3_url}

        elif content_type == 'video' and content.startswith('s3://') and not file_data:
            # This is a video generated by another service, stored in another S3 bucket.
            # Copy it to our media bucket to keep a copy.
            
            # Parse source URI
            source_path = content[5:]
            source_bucket, source_key = source_path.split('/', 1)
            
            # Create a new file name for our bucket
            file_extension = os.path.splitext(source_key)[1] # e.g. '.mp4'
            file_name = f"{session_id}/{str(uuid.uuid4())}{file_extension}"
            
            # Copy object
            copy_source = {'Bucket': source_bucket, 'Key': source_key}
            
            await loop.run_in_executor(None, lambda: self.s3_client.copy_object(
                CopySource=copy_source,
                Bucket=self.media_bucket,
                Key=file_name
            ))
            
            # Store the NEW S3 URL in the DynamoDB item
            s3_url = f"s3://{self.media_bucket}/{file_name}"
            entry['Content'] = {'S': s3_url}

        await loop.run_in_executor(None, lambda: self.dynamodb_client.put_item(
            TableName=self.conversation_table,
            Item=entry
        ))

        return s3_url

    async def get_conversation_history(self, session_id: str):
        """Retrieves and prepares conversation history for the LLM."""
        loop = asyncio.get_event_loop()

        try:
            response = await loop.run_in_executor(None, lambda: self.dynamodb_client.query(
                TableName=self.conversation_table,
                KeyConditionExpression='SessionId = :s_id',
                ExpressionAttributeValues={
                    ':s_id': {'S': session_id}
                },
                # Order by Timestamp ascending
                ScanIndexForward=True
            ))
        except ClientError as e:
            print(e.response['Error']['Message'])
            return []

        history = []
        for item in response['Items']:
            content_type = item['ContentType']['S']
            user_id = item['UserId']['S']
            content = item['Content']['S']

            entry = {
                'user_id': user_id,
                'content': content,
                'type': content_type,
            }
            
            # For media, the application must fetch the data from S3
            if content_type in ['image', 'video']:
                s3_url = content
                s3_path = s3_url.replace(f"s3://{self.media_bucket}/", "", 1)
                bucket, key = self.media_bucket, s3_path
                
                entry['source'] = {
                    's3Location': {
                        'bucket': bucket,
                        'key': key
                    }
                }
                entry['url'] = s3_url
            else:
                # For text, add 'text' field for compatibility
                entry['text'] = content
            
            history.append(entry)
        
        return history
